{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II3FlJV4sqBG"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import rasterio as rio\n",
        "import rasterio.mask as rio_mask\n",
        "from rasterio.vrt import WarpedVRT\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "import string\n",
        "from osgeo import gdal\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "plt.ioff()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_Ldy9T_s1Ou"
      },
      "outputs": [],
      "source": [
        "#set path\n",
        "src_path = Path(\"/path/S2A_T06VWP_HS.VRT\") #this is path for Simulated image (VRT file generated using Simulation.ipynb)\n",
        "ply_path = Path(\"/path/training_data.geojson\") #set path to the training data\n",
        "dem_path = Path(\"/path/DEMlayer.tif\") #Tiff file generated using DEM_preprocessing.ipynb\n",
        "resampling_alg = 1\n",
        "dst_tag = \"Sample_Region\"\n",
        "dst_dir = Path(r\"/path/predict_normalise\") #set output path\n",
        "tiles_dir = dst_dir / \"Tiles\"\n",
        "results_dir = dst_dir / \"Evaluations\"\n",
        "tiles_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "results_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "id_attr = 'class_id' # Attribute name where class_id is stored in training data\n",
        "name_attr = 'veg_class'\n",
        "vrt_path = dst_dir / \"Training_Samples.VRT\"\n",
        "data_path = dst_dir / \"Data.npz\"\n",
        "model_path = dst_dir / \"RandomForest.joblib\"\n",
        "train_validation_ratio = '70:30'\n",
        "data_index_path = dst_dir / \"Data_Index.npz\"\n",
        "shuffle_data = True\n",
        "n_samples = None\n",
        "\n",
        "#parameters for NDVI\n",
        "nir_bid = 96\n",
        "red_bid = 56\n",
        "ndvi_ll = 0.3\n",
        "ndvi_ul = 1.0\n",
        "\n",
        "class_ledger = dict()\n",
        "\n",
        "assert src_path.is_file()\n",
        "assert ply_path.is_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x54JBwYQspl-"
      },
      "outputs": [],
      "source": [
        "print (src.transform)\n",
        "print (\"=====\")\n",
        "print (vrt_dem.transform)\n",
        "print (imask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8euCyKmSeRW"
      },
      "source": [
        "## `Clip` Raster using `Polygons` and save the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NllpnrI_M_EF"
      },
      "outputs": [],
      "source": [
        "with fiona.open(ply_path, 'r') as ply:\n",
        "  feature_id = 0\n",
        "  sample_tiles = list() \n",
        "  for feature in tqdm(list(ply)):\n",
        "    polygon = feature['geometry']\n",
        "    c_id = feature['properties'][id_attr]\n",
        "    class_ledger[c_id] = {'Name': feature['properties'][name_attr]}\n",
        "    with rio.open(src_path, 'r') as src, rio.open(dem_path, 'r') as dem:\n",
        "      assert src.crs == dem.crs, \"CRS Mismatch!\"\n",
        "      with WarpedVRT(\n",
        "        dem, \n",
        "        height=src.height, \n",
        "        width=src.width,\n",
        "        transform=src.transform,\n",
        "        resampling=resampling_alg,\n",
        "      ) as vrt_dem:\n",
        "        #print(vrt_dem.meta)\n",
        "       #print(src.meta)\n",
        "        meta = src.meta.copy()\n",
        "        dst_img, dst_transform = rio_mask.mask(\n",
        "          dataset=src, \n",
        "          shapes=(polygon,), \n",
        "          invert=False,\n",
        "          all_touched=False,\n",
        "          crop=True,\n",
        "          filled=False\n",
        "        )\n",
        "        dst_dem, dem_transform = rio_mask.mask(\n",
        "          dataset=vrt_dem, \n",
        "          shapes=(polygon,), \n",
        "          invert=False,\n",
        "          all_touched=False,\n",
        "          crop=True,\n",
        "          filled=False\n",
        "        )\n",
        "        nir = dst_img[nir_bid]\n",
        "        nir_mask = nir == src.nodata\n",
        "        nir = nir.astype(np.float32)\n",
        "        nir[nir_mask] = np.nan\n",
        "        red = dst_img[red_bid]\n",
        "        red_mask = red == src.nodata\n",
        "        red = red.astype(np.float32)\n",
        "        red[red_mask] = np.nan\n",
        "        denominator = nir + red\n",
        "        denominator[denominator==0] = np.nan\n",
        "        nominator = nir - red\n",
        "        ndvi = nominator / denominator\n",
        "        ndvi_mask = np.logical_or(\n",
        "          (ndvi < ndvi_ll),\n",
        "          (ndvi > ndvi_ul)\n",
        "        )\n",
        "        imask = np.any(dst_img.mask, axis=0)\n",
        "        dmask = np.any(dst_dem.mask, axis=0)\n",
        "        imask = np.logical_or(dmask, imask)\n",
        "        imask = np.logical_or(ndvi_mask, imask)\n",
        "        dst_img.mask = np.tile(imask, (dst_img.shape[0], 1, 1))\n",
        "        dst_dem.mask = np.tile(imask, (dst_dem.shape[0], 1, 1))\n",
        "        dst_dem = dst_dem.astype(dst_img.dtype)\n",
        "        dst_dem.fill_value = dst_img.fill_value\n",
        "        dst_img = np.concatenate((dst_img, dst_dem), axis=0)\n",
        "\n",
        "        meta['count'], meta['height'], meta['width'] = dst_img.shape\n",
        "        meta['driver'] = 'GTiff'\n",
        "        meta['transform'] = dst_transform\n",
        "        dst_path = tiles_dir / \"{}_{}.{}\".format(\n",
        "          dst_tag, feature_id, 'tiff'\n",
        "        )\n",
        "        with rio.open(dst_path, 'w', **meta) as dst:\n",
        "          dst.write(dst_img.filled())\n",
        "          dst.update_tags(class_id=c_id)\n",
        "        sample_tiles.append(dst_path)\n",
        "    feature_id += 1\n",
        "  wd = Path.cwd() \n",
        "  os.chdir(dst_dir)\n",
        "  tile_paths = [\n",
        "    str(tile_path.relative_to(dst_dir)) for tile_path in sample_tiles\n",
        "  ]\n",
        "  vrt_options = gdal.BuildVRTOptions(resampleAlg='near', addAlpha=False)\n",
        "  ds = gdal.BuildVRT(\n",
        "    str(vrt_path.relative_to(dst_dir)), tile_paths, options=vrt_options\n",
        "  )\n",
        "  ds.FlushCache()\n",
        "  os.chdir(wd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHzqoUoXsge"
      },
      "source": [
        "## Prepare `acronyms` for class names\n",
        "### Makes it easy to label plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-0mmCo4XzZE"
      },
      "outputs": [],
      "source": [
        "cls_i = list(class_ledger.keys())\n",
        "n_classes = len(cls_i)\n",
        "assert n_classes <= 26\n",
        "\n",
        "# Needs to be changed if n_classes > 26\n",
        "cls_a = list(string.ascii_uppercase)[:n_classes] \n",
        "cls_n = list()\n",
        "for i in range(n_classes):\n",
        "  class_ledger[cls_i[i]]['Acronym'] = cls_a[i]\n",
        "  cls_n.append(class_ledger[cls_i[i]]['Name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihr1cmmeVYy1"
      },
      "source": [
        "## Prepare `Training Data`,\n",
        "### Collate training samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWNze5lJVYMy"
      },
      "outputs": [],
      "source": [
        "sample_arrays = list()\n",
        "target_arrays = list()\n",
        "for tile_path in sample_tiles:\n",
        "  with rio.open(tile_path, 'r') as tile:\n",
        "    tile_arr = tile.read(masked=True)\n",
        "    n_bands = tile_arr.shape[0]\n",
        "    mask = np.any(a=tile_arr.mask, axis=0, keepdims=False).ravel(order='C')\n",
        "    arr = (tile_arr.filled()).reshape((n_bands, -1), order='C')\n",
        "    arr = arr[:, np.logical_not(mask)]\n",
        "    arr = np.moveaxis(arr, 0, -1)\n",
        "    sample_arrays.append(arr)\n",
        "    target_arrays.append(\n",
        "      np.full(\n",
        "        shape=(arr.shape[0],), \n",
        "        fill_value=tile.tags()['class_id'],\n",
        "        dtype=np.uint8\n",
        "      )\n",
        "    )\n",
        "\n",
        "sample_array = np.concatenate(sample_arrays, axis=0)\n",
        "target_array = np.concatenate(target_arrays, axis=0)\n",
        "assert sample_array.shape[0] == target_array.shape[0]\n",
        "n_samples = sample_array.shape[0]\n",
        "\n",
        "with open(data_path, 'wb') as dat:\n",
        "  np.savez_compressed(\n",
        "    file=dat,\n",
        "    X=sample_array,\n",
        "    Y=target_array\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYJkjGklE51b"
      },
      "source": [
        "## `Shuffle` and `Split` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CW9WJl_FFCa"
      },
      "outputs": [],
      "source": [
        "if shuffle_data is True:\n",
        "  # TODO: Train Validation Split\n",
        "  row_indexes = np.arange(start=0, stop=n_samples, step=1)\n",
        "  np.random.shuffle(row_indexes)\n",
        "  ratio_parts = [float(p) for p in train_validation_ratio.split(':')]\n",
        "  n_train = int(\n",
        "    np.round(((n_samples * ratio_parts[0]) / sum(ratio_parts)), 0)\n",
        "  )\n",
        "  train_indexes = row_indexes[:n_train]\n",
        "  validation_indexes = row_indexes[n_train:]\n",
        "  with open(data_index_path, 'wb') as ip:\n",
        "    np.savez_compressed(\n",
        "      file=ip,\n",
        "      train=train_indexes,\n",
        "      validation=validation_indexes\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS_XFabqORwq"
      },
      "source": [
        "## Set `parameters` for `Model`\n",
        "### Only change the parameters you need\n",
        "### Default values are provided in the comments on the right hand side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uweNrx1NOZBC"
      },
      "outputs": [],
      "source": [
        "model_conf = {\n",
        "  'n_estimators': 500,  # 100\n",
        "  'criterion': 'gini',  # 'gini'\n",
        "  'max_depth': None,  # None\n",
        "  'min_samples_split': 2,  # 2\n",
        "  'min_samples_leaf': 1,  # 1\n",
        "  'min_weight_fraction_leaf': 0.0,  # 0.0\n",
        "  'max_features': 'auto',  # 'auto'\n",
        "  'max_leaf_nodes': None,  # None\n",
        "  'min_impurity_decrease': 0.0,  # 0.0\n",
        "  'min_impurity_split': None,  # None\n",
        "  'bootstrap': True,  # True\n",
        "  'oob_score': True,  # False\n",
        "  'n_jobs': -1,  # None\n",
        "  'random_state': None,  # None\n",
        "  'verbose': 0,  # 0\n",
        "  'warm_start': False,  # False\n",
        "  'class_weight': None,  # None\n",
        "  'ccp_alpha': 0.0,  # 0.0\n",
        "  'max_samples': None  # None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujEjmQSpNnkA"
      },
      "source": [
        "## Initialize `Model` for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkUH98KdNmj4"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(**model_conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duM9lCbASwRD"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_0PToQqS0nS"
      },
      "outputs": [],
      "source": [
        "with open(data_path, 'rb') as dp:\n",
        "  data_archive = np.load(file=dp, allow_pickle=False)\n",
        "  data_x = data_archive['X']\n",
        "  data_y = data_archive['Y']\n",
        "with open(data_index_path, 'rb') as idxp:\n",
        "  index_archive = np.load(file=idxp, allow_pickle=False)\n",
        "  t_idx = index_archive['train']\n",
        "  v_idx = index_archive['validation']\n",
        "train_x, train_y = data_x[t_idx, :], data_y[t_idx]\n",
        "validation_x, validation_y = data_x[v_idx, :], data_y[v_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmzYoRX_V74e"
      },
      "source": [
        "## `Train` the `Classifier`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7ZxRofZWBsf"
      },
      "outputs": [],
      "source": [
        "print(train_x.shape, train_y.shape)\n",
        "clf.fit(X=train_x, y=train_y, sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnerzRI7X9fW"
      },
      "source": [
        "## `Save` the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k8ps9iGX80-"
      },
      "outputs": [],
      "source": [
        "with open(model_path, 'wb') as mp:\n",
        "  joblib.dump(value=clf, filename=mp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxtr3Jbf5Iya"
      },
      "source": [
        "## Define a `function` to calculate various `metrics` from `confusion_metrics\n",
        "### Takes `normalized confusion matrix` as input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4RIUTR_5U6y"
      },
      "outputs": [],
      "source": [
        "def eval_cm(confusion_matrix, class_refs=None):\n",
        "  fp = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "  fn = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "  tp = np.diag(confusion_matrix)\n",
        "  tn = confusion_matrix.sum() - (fp + fn + tp)\n",
        "\n",
        "  # Sensitivity, hit rate, recall, or true positive rate\n",
        "  a, b = tp, (tp + fn)\n",
        "  tpr = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # False negative rate\n",
        "  a, b = fn, (tp + fn)\n",
        "  fnr = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Specificity or true negative rate\n",
        "  a, b = tn, (tn + fp)\n",
        "  tnr = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Fall out or false positive rate\n",
        "  a, b = fp, (tn + fp)\n",
        "  fpr = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Precision or positive predictive value\n",
        "  a, b = tp, (tp + fp)\n",
        "  ppv = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # False discovery rate\n",
        "  a, b = fp, (tp + fp)\n",
        "  fdr = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Negative predictive value\n",
        "  a, b = tn, (tn + fn)\n",
        "  npv = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Intersection over Union\n",
        "  a, b = tp, (tp + fn + fp)\n",
        "  iou = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # F1 score\n",
        "  a, b = (2 * (ppv * tpr)), (ppv + tpr)\n",
        "  f1 = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Overall accuracy\n",
        "  a, b = (tp + tn), (tp + fp + fn + tn)\n",
        "  acc = np.divide(a, b, out=np.full_like(a, fill_value=np.nan), where=b!=0)\n",
        "  # Balanced Accuracy\n",
        "  bacc = 0.5 * (tpr + tnr)\n",
        "\n",
        "  metrics_df = pd.DataFrame(\n",
        "    data=np.stack(\n",
        "      (tpr, tnr, ppv, npv, fpr, fnr, fdr, iou, f1, bacc, acc),\n",
        "      axis=-1\n",
        "    ), \n",
        "    columns=(\n",
        "      \"TPR\", \"TNR\", \"PPV\", \"NPV\", \"FPR\", \"FNR\", \n",
        "      \"FDR\", \"IoU\", \"F1\", \"BACC\", \"ACC\"\n",
        "    ),\n",
        "    index=class_refs\n",
        "  )\n",
        "  metrics_df.loc['Mean'] = metrics_df.mean()\n",
        "  return metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyTmNCSdw5OB"
      },
      "source": [
        "## Evaluate `Trained Model` using various `metrics`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRa5mdHoxBr1"
      },
      "outputs": [],
      "source": [
        "feature_importance = clf.feature_importances_\n",
        "oob_score = clf.oob_score_\n",
        "train_yy = clf.predict(X=train_x)\n",
        "validation_yy = clf.predict(X=validation_x)\n",
        "train_yp = clf.predict_proba(train_x)\n",
        "validation_yp = clf.predict_proba(validation_x)\n",
        "\n",
        "train_cm = confusion_matrix(\n",
        "  y_true=train_y, \n",
        "  y_pred=train_yy,  \n",
        "  labels=cls_i, \n",
        "  sample_weight=None, \n",
        "  normalize=None\n",
        ")\n",
        "validation_cm = confusion_matrix(\n",
        "  y_true=validation_y, \n",
        "  y_pred=validation_yy,  \n",
        "  labels=cls_i, \n",
        "  sample_weight=None, \n",
        "  normalize=None\n",
        ")\n",
        "\n",
        "train_cm_norm = confusion_matrix(\n",
        "  y_true=train_y, \n",
        "  y_pred=train_yy,  \n",
        "  labels=cls_i, \n",
        "  sample_weight=None, \n",
        "  normalize=\"all\"\n",
        ")\n",
        "validation_cm_norm = confusion_matrix(\n",
        "  y_true=validation_y, \n",
        "  y_pred=validation_yy,  \n",
        "  labels=cls_i, \n",
        "  sample_weight=None, \n",
        "  normalize=\"all\"\n",
        ")\n",
        "\n",
        "train_k = cohen_kappa_score(\n",
        "  y1=train_y,\n",
        "  y2=train_yy,\n",
        "  labels=None, \n",
        "  weights=None, \n",
        "  sample_weight=None\n",
        ")\n",
        "validation_k = cohen_kappa_score(\n",
        "  y1=validation_y,\n",
        "  y2=validation_yy,\n",
        "  labels=None, \n",
        "  weights=None, \n",
        "  sample_weight=None\n",
        ")\n",
        "\n",
        "train_mcc = matthews_corrcoef(\n",
        "  y_true=train_y,\n",
        "  y_pred=train_yy,\n",
        "  sample_weight=None\n",
        ")\n",
        "validation_mcc = matthews_corrcoef(\n",
        "  y_true=validation_y,\n",
        "  y_pred=validation_yy,\n",
        "  sample_weight=None\n",
        ")\n",
        "\n",
        "train_roc_auc = roc_auc_score(\n",
        "  y_true=train_y, y_score=train_yp, average='macro', multi_class='ovr'\n",
        ")\n",
        "validation_roc_auc = roc_auc_score(\n",
        "  y_true=train_y, y_score=train_yp, average='macro', multi_class='ovr'\n",
        ")\n",
        "\n",
        "#train_pr_auc = average_precision_score(train_y, train_yp)\n",
        "#validation_pr_auc = average_precision_score(validation_y, validation_yp)\n",
        "\n",
        "train_ll = log_loss(y_true=train_y, y_pred=train_yp, normalize=True)\n",
        "validation_ll = log_loss(\n",
        "  y_true=validation_y, y_pred=validation_yp, normalize=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlaTZHbAqw4"
      },
      "source": [
        "## Save some `metrics`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kqbMZLPAuxn"
      },
      "outputs": [],
      "source": [
        "train_df = eval_cm(train_cm_norm, cls_a)\n",
        "validation_df = eval_cm(validation_cm_norm, cls_a)\n",
        "cor_df = pd.DataFrame(\n",
        "  columns=[\n",
        "    'MCC', 'Kappa', 'CE_Loss'\n",
        "  ]\n",
        ")\n",
        "cor_df.loc['Train'] = [\n",
        "  train_mcc, train_k, train_ll\n",
        "]\n",
        "cor_df.loc['Validation'] = [\n",
        "  validation_mcc, validation_k, validation_ll\n",
        "]\n",
        "cmt_df = pd.DataFrame(\n",
        "  data=train_cm,\n",
        "  index=cls_n,\n",
        "  columns=cls_n\n",
        ")\n",
        "cmv_df = pd.DataFrame(\n",
        "  data=validation_cm,\n",
        "  index=cls_n,\n",
        "  columns=cls_n\n",
        ")\n",
        "oob_df = pd.DataFrame([oob_score,], columns=['OOB_Score',])\n",
        "with pd.ExcelWriter((results_dir / 'Metrics.xlsx')) as writer:\n",
        "  cmt_df.to_excel(\n",
        "    writer, sheet_name='CM_Train',\n",
        "    index=True, index_label=\"True / Prediction\"\n",
        "  )\n",
        "  cmv_df.to_excel(\n",
        "    writer, sheet_name='CM_Validation',\n",
        "    index=True, index_label=\"True / Prediction\"\n",
        "  )\n",
        "  train_df.to_excel(\n",
        "    writer, sheet_name='Training',\n",
        "    index=True, index_label=\"Class_Indicator\"\n",
        "  )\n",
        "  validation_df.to_excel(\n",
        "    writer, sheet_name='Validation',\n",
        "    index=True, index_label=\"Class_Indicator\"\n",
        "  )\n",
        "  cor_df.to_excel(\n",
        "    writer, sheet_name='Evaluation Coeeficients',\n",
        "    index=True, index_label='Type'\n",
        "  )\n",
        "  oob_df.to_excel(\n",
        "    writer, sheet_name='OOB',\n",
        "    index=False\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVGvEaWqLeMS"
      },
      "source": [
        "## Plot `Confusion Metrix`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wrg0J51LmIo"
      },
      "outputs": [],
      "source": [
        "#Plot Confusion Metrix\n",
        "fig = plt.figure(figsize=(15,18),dpi=500)\n",
        "ax1 = fig.add_subplot(111)\n",
        "sns.heatmap(\n",
        "  data=train_cm,\n",
        "  #vmin=0.0,\n",
        "  #vmax=1.0,\n",
        "  center=None,\n",
        "  cmap=cm.get_cmap(name='magma_r'),\n",
        "  robust=False,\n",
        "  annot=True,\n",
        "  fmt='.0f',\n",
        "  cbar=True,\n",
        "  xticklabels=cls_a,\n",
        "  yticklabels=cls_a,\n",
        "  square=True,\n",
        "  ax=ax1\n",
        ")\n",
        "ax1.set_xlabel(\"Predicted Labels\")\n",
        "ax1.set_ylabel(\"True Labels\")\n",
        "ax1.set_title(label=\"Confusion Matrix: Training Data\")\n",
        "fig.savefig(fname=(results_dir / \"Confusion_Matrix_Train.pdf\"), dpi=600)\n",
        "\n",
        "fig = plt.figure(figsize=(15,18),dpi=500)\n",
        "ax2 = fig.add_subplot(111)\n",
        "sns.heatmap(\n",
        "  data=validation_cm,\n",
        "  #vmin=0.0,\n",
        "  #vmax=1.0,\n",
        "  center=None,\n",
        "  cmap=cm.get_cmap(name='magma_r'),\n",
        "  robust=False,\n",
        "  annot=True,\n",
        "  fmt='.0f',\n",
        "  cbar=True,\n",
        "  xticklabels=cls_a,\n",
        "  yticklabels=cls_a,\n",
        "  square=True,\n",
        "  ax=ax2\n",
        ")\n",
        "ax2.set_xlabel(\"Predicted Labels\")\n",
        "ax2.set_ylabel(\"True Labels\")\n",
        "ax2.set_title(label=\"Confusion Matrix: Validation Data\")\n",
        "fig.savefig(fname=(results_dir / \"Confusion_Matrix_Validation.pdf\"), dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm3ic5RTnT8i"
      },
      "source": [
        "## Plot `Feature Impotance`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuGFAoFRlI4H"
      },
      "outputs": [],
      "source": [
        "# No. features to plot. \n",
        "# Plotting all bands would be difficult to fit in a single plot\n",
        "n_features = 20\n",
        "sorted_index = np.argsort(a=feature_importance)\n",
        "bad_bidx = sorted_index[:n_features]\n",
        "bad_vals = feature_importance[bad_bidx]\n",
        "good_bidx = sorted_index[-n_features:]\n",
        "good_vals = feature_importance[good_bidx]\n",
        "bad_bidx += 1\n",
        "good_bidx += 1\n",
        "x_ticks = np.arange(n_features)\n",
        "\n",
        "fig = plt.figure(figsize=(16, 3), dpi=500)\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax1.bar(\n",
        "  x=x_ticks, \n",
        "  height=good_vals, \n",
        "  tick_label=good_bidx,\n",
        "  width=0.25, \n",
        "  bottom=0, \n",
        "  align='center',\n",
        "  color='C0'\n",
        ")\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.set_xlabel(\"Bands\")\n",
        "ax1.set_ylabel(\"Importance\")\n",
        "ax1.set_title(label=\"{} Most Important Bands\".format(n_features))\n",
        "\n",
        "ax2.bar(\n",
        "  x=x_ticks, \n",
        "  height=bad_vals, \n",
        "  tick_label=bad_bidx,\n",
        "  width=0.25, \n",
        "  bottom=0, \n",
        "  align='center',\n",
        "  color='C1'\n",
        ")\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.set_xlabel(\"Bands\")\n",
        "ax2.set_ylabel(\"Importance\")\n",
        "ax2.set_title(label=\"{} Least Important Bands\".format(n_features))\n",
        "fig.savefig(fname=(results_dir / \"Feature_Importance.pdf\"), dpi=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GllidxjmjaYo"
      },
      "source": [
        "## `Color` generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztJzFjk6jeLx"
      },
      "outputs": [],
      "source": [
        "def color_generator(n, name='tab20'):\n",
        "  return cm.get_cmap(name, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4ne_ZSVkq5M"
      },
      "source": [
        "## Generate `color palette` for classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPeUYg5xk6lK"
      },
      "outputs": [],
      "source": [
        "cg = color_generator(n_classes)\n",
        "for i in range(n_classes):\n",
        "  r, g, b, a = cg(i)\n",
        "  class_ledger[cls_i[i]]['RED'] = r\n",
        "  class_ledger[cls_i[i]]['GREEN'] = g\n",
        "  class_ledger[cls_i[i]]['BLUE'] = b\n",
        "  class_ledger[cls_i[i]]['ALPHA'] = a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CduJZ0xWsgdY"
      },
      "source": [
        "## Save `meta` to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLpMPk-nspOj"
      },
      "outputs": [],
      "source": [
        "with open((results_dir / 'Meta_Info.json'), 'w',encoding=\"utf-8\") as fp:\n",
        "  json.dump(class_ledger, fp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}